{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e99c9a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not set threads: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from contextlib import nullcontext\n",
    "\n",
    "try:\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)\n",
    "    print(\"Threads set: num_threads=1, interop_threads=1\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not set threads: {e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "DATA_DIR = \"data\"               # your dataset root\n",
    "OUT_DIR  = \"runs/font_densenet\"\n",
    "BATCH_SIZE = 32                 # try 32; if OOM on MPS, use 16\n",
    "EPOCHS = 12                     # 3-4 frozen + 8-9 unfrozen is a good start\n",
    "VAL_SPLIT = 0.15\n",
    "SEED = 42\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0                 # macOS often safer at 0/2\n",
    "PIN_MEMORY = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c35946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transforms\n",
    "# ----------------------------\n",
    "# For font imagery: preserve crisp edges, small geometric jitter helps generalize\n",
    "# Images are black text on white; we still normalize to ImageNet stats since we use pretrained weights.\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),            # ensure 3-ch\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), antialias=True),\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), shear=(-2,2), fill=255),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256, antialias=True),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec336a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Inter', 'Lato', 'Merriweather', 'Montserrat', 'Nunito', 'Open_Sans', 'Oswald', 'Playfair_Display', 'Poppins', 'Raleway', 'Roboto', 'Roboto_Condensed', 'Roboto_Mono', 'Source_Sans_Pro', 'Ubuntu']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Dataset / Split\n",
    "# ----------------------------\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)  # we'll swap tfms for val subset later\n",
    "num_classes = len(full_ds.classes)\n",
    "print(\"Classes:\", full_ds.classes)\n",
    "\n",
    "# save class mapping for inference later\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "with open(Path(OUT_DIR) / \"classes.json\", \"w\") as f:\n",
    "    json.dump(full_ds.classes, f)\n",
    "\n",
    "n_total = len(full_ds)\n",
    "n_val = int(math.ceil(n_total * VAL_SPLIT))\n",
    "n_train = n_total - n_val\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=g)\n",
    "\n",
    "# assign val transforms\n",
    "val_ds.dataset = datasets.ImageFolder(DATA_DIR, transform=val_tfms)\n",
    "# keep the same class_to_idx mapping\n",
    "val_ds.dataset.class_to_idx = full_ds.class_to_idx\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "460d0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Device (Apple Silicon friendly)\n",
    "# ----------------------------\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Model (ResNet-18) + head\n",
    "# ----------------------------\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "440819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Optimizer / Scheduler / Loss\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Warmup with frozen backbone\n",
    "# ----------------------------\n",
    "def set_backbone_requires_grad(req: bool):\n",
    "    for name, p in model.named_parameters():\n",
    "        if name.startswith(\"fc\"):\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = req\n",
    "\n",
    "# freeze backbone for first few epochs for stability on small data\n",
    "FROZEN_EPOCHS = 3\n",
    "set_backbone_requires_grad(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "987ad009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/xdhs9djd73zb7hz3752jr1gh0000gn/T/ipykernel_57606/144524256.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/12 | train_loss 1.0623 acc 0.628 | val_loss 0.2024 acc 0.460 | 4.5s\n",
      "  ✅ Saved new best to runs/font_densenet/best.ckpt.pt (val_acc=0.460)\n",
      "Epoch 02/12 | train_loss 0.1564 acc 0.807 | val_loss 0.0334 acc 0.867 | 2.4s\n",
      "  ✅ Saved new best to runs/font_densenet/best.ckpt.pt (val_acc=0.867)\n",
      "Epoch 03/12 | train_loss 0.2529 acc 0.761 | val_loss 0.2501 acc 0.735 | 2.3s\n",
      "Epoch 04/12 | train_loss 0.0970 acc 0.845 | val_loss 0.0023 acc 0.982 | 5.5s\n",
      "  ✅ Saved new best to runs/font_densenet/best.ckpt.pt (val_acc=0.982)\n",
      "Epoch 05/12 | train_loss 0.0712 acc 0.874 | val_loss 0.1105 acc 0.991 | 3.4s\n",
      "  ✅ Saved new best to runs/font_densenet/best.ckpt.pt (val_acc=0.991)\n",
      "Epoch 06/12 | train_loss 0.0847 acc 0.892 | val_loss 0.0084 acc 0.894 | 3.4s\n",
      "Epoch 07/12 | train_loss 0.0635 acc 0.907 | val_loss 0.0954 acc 0.965 | 3.4s\n",
      "Epoch 08/12 | train_loss 0.0453 acc 0.934 | val_loss 0.1599 acc 0.796 | 3.5s\n",
      "Epoch 09/12 | train_loss 0.0441 acc 0.926 | val_loss 0.0074 acc 0.965 | 3.4s\n",
      "Epoch 10/12 | train_loss 0.0716 acc 0.912 | val_loss 0.1229 acc 0.876 | 3.4s\n",
      "Epoch 11/12 | train_loss 0.0484 acc 0.931 | val_loss 0.1241 acc 0.832 | 3.4s\n",
      "Epoch 12/12 | train_loss 0.0511 acc 0.917 | val_loss 0.2237 acc 0.743 | 3.3s\n",
      "Best val acc: 0.991\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# AMP for speed (CUDA only, MPS/CPU use no-op)\n",
    "# ----------------------------\n",
    "use_cuda_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n",
    "\n",
    "def maybe_autocast():\n",
    "    # Autocast only on CUDA; use no-op on MPS/CPU\n",
    "    return torch.cuda.amp.autocast(dtype=torch.float16) if use_cuda_amp else nullcontext()\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval loops\n",
    "# ----------------------------\n",
    "best_val_acc = 0.0\n",
    "best_ckpt = Path(OUT_DIR) / \"best.ckpt.pt\"\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(mode=train)\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with maybe_autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            if train:\n",
    "                if use_cuda_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total if total else 0.0\n",
    "    acc = correct / total if total else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # unfreeze after warmup\n",
    "    if epoch == FROZEN_EPOCHS:\n",
    "        set_backbone_requires_grad(True)\n",
    "\n",
    "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc = run_epoch(val_loader, train=False)\n",
    "    scheduler.step()\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "          f\"train_loss {train_loss:.4f} acc {train_acc:.3f} | \"\n",
    "          f\"val_loss {val_loss:.4f} acc {val_acc:.3f} | {dt:.1f}s\")\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"classes\": full_ds.classes,\n",
    "            \"val_acc\": val_acc\n",
    "        }, best_ckpt)\n",
    "        print(f\"  ✅ Saved new best to {best_ckpt} (val_acc={val_acc:.3f})\")\n",
    "\n",
    "print(f\"Best val acc: {best_val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fb9ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fonts-arm64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
