{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e99c9a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, json, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from contextlib import nullcontext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2835e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce thread contention (can prevent hangs on macOS/Accelerate)\n",
    "import torch\n",
    "try:\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)\n",
    "    print(\"Threads set: num_threads=1, interop_threads=1\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not set threads: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "405ad185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "DATA_DIR = \"data\"               # your dataset root\n",
    "OUT_DIR  = \"runs/font_densenet\"\n",
    "BATCH_SIZE = 32                 # try 32; if OOM on MPS, use 16\n",
    "EPOCHS = 12                     # 3-4 frozen + 8-9 unfrozen is a good start\n",
    "VAL_SPLIT = 0.15\n",
    "SEED = 42\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0                 # macOS often safer at 0/2\n",
    "PIN_MEMORY = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6616c304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Device (Apple Silicon friendly)\n",
    "# ----------------------------\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c35946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transforms\n",
    "# ----------------------------\n",
    "# For font imagery: preserve crisp edges, small geometric jitter helps generalize\n",
    "# Images are black text on white; we still normalize to ImageNet stats since we use pretrained weights.\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),            # ensure 3-ch\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), antialias=True),\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), shear=(-2,2), fill=255),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256, antialias=True),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec336a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Inter', 'Lato', 'Merriweather', 'Montserrat', 'Nunito', 'Open_Sans', 'Oswald', 'Playfair_Display', 'Poppins', 'Raleway', 'Roboto', 'Roboto_Condensed', 'Roboto_Mono', 'Source_Sans_Pro', 'Ubuntu']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Dataset / Split\n",
    "# ----------------------------\n",
    "full_ds = datasets.ImageFolder(DATA_DIR, transform=train_tfms)  # we'll swap tfms for val subset later\n",
    "num_classes = len(full_ds.classes)\n",
    "print(\"Classes:\", full_ds.classes)\n",
    "\n",
    "# save class mapping for inference later\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "with open(Path(OUT_DIR) / \"classes.json\", \"w\") as f:\n",
    "    json.dump(full_ds.classes, f)\n",
    "\n",
    "n_total = len(full_ds)\n",
    "n_val = int(math.ceil(n_total * VAL_SPLIT))\n",
    "n_train = n_total - n_val\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "train_ds, val_ds = random_split(full_ds, [n_train, n_val], generator=g)\n",
    "\n",
    "# assign val transforms\n",
    "val_ds.dataset = datasets.ImageFolder(DATA_DIR, transform=val_tfms)\n",
    "# keep the same class_to_idx mapping\n",
    "val_ds.dataset.class_to_idx = full_ds.class_to_idx\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "460d0133",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# Model (ResNet-18) + head\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241m.\u001b[39mresnet18(weights\u001b[38;5;241m=\u001b[39mmodels\u001b[38;5;241m.\u001b[39mResNet18_Weights\u001b[38;5;241m.\u001b[39mIMAGENET1K_V1)\n\u001b[1;32m      5\u001b[0m in_features \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfc\u001b[38;5;241m.\u001b[39min_features\n\u001b[1;32m      6\u001b[0m model\u001b[38;5;241m.\u001b[39mfc \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(in_features, num_classes)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Model (ResNet-18) + head\n",
    "# ----------------------------\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "440819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Optimizer / Scheduler / Loss\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Warmup with frozen backbone\n",
    "# ----------------------------\n",
    "def set_backbone_requires_grad(req: bool):\n",
    "    for name, p in model.named_parameters():\n",
    "        if not name.startswith(\"classifier\"):\n",
    "            p.requires_grad = req\n",
    "\n",
    "# freeze backbone for first few epochs for stability on small data\n",
    "FROZEN_EPOCHS = 3\n",
    "set_backbone_requires_grad(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987ad009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# AMP for speed (CUDA only, MPS/CPU use no-op)\n",
    "# ----------------------------\n",
    "use_cuda_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n",
    "\n",
    "def maybe_autocast():\n",
    "    # Autocast only on CUDA; use no-op on MPS/CPU\n",
    "    return torch.cuda.amp.autocast(dtype=torch.float16) if use_cuda_amp else nullcontext()\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval loops\n",
    "# ----------------------------\n",
    "best_val_acc = 0.0\n",
    "best_ckpt = Path(OUT_DIR) / \"best.ckpt.pt\"\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(mode=train)\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with maybe_autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            if train:\n",
    "                if use_cuda_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total if total else 0.0\n",
    "    acc = correct / total if total else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # unfreeze after warmup\n",
    "    if epoch == FROZEN_EPOCHS:\n",
    "        set_backbone_requires_grad(True)\n",
    "\n",
    "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc = run_epoch(val_loader, train=False)\n",
    "    scheduler.step()\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "          f\"train_loss {train_loss:.4f} acc {train_acc:.3f} | \"\n",
    "          f\"val_loss {val_loss:.4f} acc {val_acc:.3f} | {dt:.1f}s\")\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"classes\": full_ds.classes,\n",
    "            \"val_acc\": val_acc\n",
    "        }, best_ckpt)\n",
    "        print(f\"  ✅ Saved new best to {best_ckpt} (val_acc={val_acc:.3f})\")\n",
    "\n",
    "print(f\"Best val acc: {best_val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f746565",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12ff66a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing data loader...\n",
      "Dataset size: 750\n",
      "Train batches: 20\n",
      "Val batches: 4\n",
      "Loading first batch...\n",
      "Batch shape: torch.Size([32, 3, 224, 224]), torch.Size([32])\n",
      "✅ Data loader works!\n"
     ]
    }
   ],
   "source": [
    "# Debug: Test data loader\n",
    "print(\"Testing data loader...\")\n",
    "print(f\"Dataset size: {len(full_ds)}\")\n",
    "print(f\"Train batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "\n",
    "# Test first batch\n",
    "print(\"Loading first batch...\")\n",
    "try:\n",
    "    first_batch = next(iter(train_loader))\n",
    "    print(f\"Batch shape: {first_batch[0].shape}, {first_batch[1].shape}\")\n",
    "    print(\"✅ Data loader works!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Data loader failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593dfcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing single batch training...\n",
      "Batch loaded: torch.Size([32, 3, 224, 224])\n",
      "Moved to device\n"
     ]
    }
   ],
   "source": [
    "use_cuda_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n",
    "\n",
    "def maybe_autocast():\n",
    "    # Autocast only on CUDA; use no-op on MPS/CPU\n",
    "    return torch.cuda.amp.autocast(dtype=torch.float16) if use_cuda_amp else nullcontext()\n",
    "\n",
    "# Quick test - single batch training\n",
    "print(\"Testing single batch training...\")\n",
    "model.train()\n",
    "try:\n",
    "    images, targets = next(iter(train_loader))\n",
    "    print(f\"Batch loaded: {images.shape}\")\n",
    "    \n",
    "    images = images.to(device, non_blocking=True)\n",
    "    targets = targets.to(device, non_blocking=True)\n",
    "    print(\"Moved to device\")\n",
    "    \n",
    "    with maybe_autocast():\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, targets)\n",
    "    print(f\"Forward pass: loss={loss.item():.4f}\")\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    print(\"✅ Single batch training works!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Single batch training failed: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae5822b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "playground",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
