{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e99c9a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not set threads: Error: cannot set number of interop threads after parallel work has started or set_num_interop_threads called\n"
     ]
    }
   ],
   "source": [
    "import os, json, math, time\n",
    "from pathlib import Path\n",
    "\n",
    "import platform\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, models, transforms\n",
    "\n",
    "from contextlib import nullcontext\n",
    "\n",
    "try:\n",
    "    torch.set_num_threads(1)\n",
    "    torch.set_num_interop_threads(1)\n",
    "    print(\"Threads set: num_threads=1, interop_threads=1\")\n",
    "except Exception as e:\n",
    "    print(f\"Could not set threads: {e}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Config\n",
    "# ----------------------------\n",
    "DATA_DIR = \"data\"               # your dataset root\n",
    "OUT_DIR  = \"runs/font_resnet\"\n",
    "BATCH_SIZE = 32                 # try 32; if OOM on MPS, use 16\n",
    "EPOCHS = 12                     # 3-4 frozen + 8-9 unfrozen is a good start\n",
    "VAL_SPLIT = 0.15\n",
    "SEED = 42\n",
    "LEARNING_RATE = 3e-4\n",
    "WEIGHT_DECAY = 1e-4\n",
    "NUM_WORKERS = 0                 # macOS often safer at 0/2\n",
    "PIN_MEMORY = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c35946ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Transforms\n",
    "# ----------------------------\n",
    "# For font imagery: preserve crisp edges, small geometric jitter helps generalize\n",
    "# Images are black text on white; we still normalize to ImageNet stats since we use pretrained weights.\n",
    "IMG_SIZE = 224\n",
    "\n",
    "train_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),            # ensure 3-ch\n",
    "    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0), antialias=True),\n",
    "    transforms.RandomAffine(degrees=2, translate=(0.02, 0.02), shear=(-2,2), fill=255),\n",
    "    transforms.RandomApply([transforms.GaussianBlur(kernel_size=3)], p=0.15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "val_tfms = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.Resize(256, antialias=True),\n",
    "    transforms.CenterCrop(IMG_SIZE),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ec336a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['Inter', 'Lato', 'Merriweather', 'Montserrat', 'Nunito', 'Open_Sans', 'Oswald', 'Playfair_Display', 'Poppins', 'Raleway', 'Roboto', 'Roboto_Condensed', 'Roboto_Mono', 'Source_Sans_Pro', 'Ubuntu']\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Dataset / Split (clone base per split)\n",
    "# ----------------------------\n",
    "full_ds = datasets.ImageFolder(DATA_DIR)  # no transform here\n",
    "num_classes = len(full_ds.classes)\n",
    "print(\"Classes:\", full_ds.classes)\n",
    "\n",
    "# save class mapping for inference later\n",
    "Path(OUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "with open(Path(OUT_DIR) / \"classes.json\", \"w\") as f:\n",
    "    json.dump(full_ds.classes, f)\n",
    "\n",
    "n_total = len(full_ds)\n",
    "n_val = int(math.ceil(n_total * VAL_SPLIT))\n",
    "n_train = n_total - n_val\n",
    "g = torch.Generator().manual_seed(SEED)\n",
    "perm = torch.randperm(n_total, generator=g).tolist()\n",
    "train_idx, val_idx = perm[:n_train], perm[n_train:]\n",
    "\n",
    "import copy\n",
    "train_base = copy.deepcopy(full_ds); train_base.transform = train_tfms\n",
    "val_base   = copy.deepcopy(full_ds); val_base.transform   = val_tfms\n",
    "\n",
    "from torch.utils.data import Subset\n",
    "train_ds = Subset(train_base, train_idx)\n",
    "val_ds   = Subset(val_base, val_idx)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)\n",
    "val_loader   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                          num_workers=NUM_WORKERS, pin_memory=PIN_MEMORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "460d0133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=15, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# Device (Apple Silicon friendly)\n",
    "# ----------------------------\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# ----------------------------\n",
    "# Model (ResNet-18) + head\n",
    "# ----------------------------\n",
    "model = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, num_classes)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "440819ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Optimizer / Scheduler / Loss\n",
    "# ----------------------------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# IMPORTANT: optimizer should only see trainable params at each phase\n",
    "optimizer = optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
    "                        lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY)\n",
    "                        \n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
    "\n",
    "HEAD_NAMES = (\"fc\", \"classifier\")\n",
    "\n",
    "def freeze_backbone_keep_head(model):\n",
    "    # freeze everything\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = False\n",
    "    # unfreeze the head (fc for ResNet, classifier for DenseNet)\n",
    "    for head_name in HEAD_NAMES:\n",
    "        head = getattr(model, head_name, None)\n",
    "        if head is not None:\n",
    "            for p in head.parameters():\n",
    "                p.requires_grad = True\n",
    "\n",
    "def unfreeze_all(model):\n",
    "    for p in model.parameters():\n",
    "        p.requires_grad = True\n",
    "\n",
    "# ----------------------------\n",
    "# Optional: Warmup with frozen backbone\n",
    "# ----------------------------\n",
    "def set_backbone_requires_grad(req: bool):\n",
    "    for name, p in model.named_parameters():\n",
    "        if name.startswith(\"fc\"):\n",
    "            p.requires_grad = True\n",
    "        else:\n",
    "            p.requires_grad = req\n",
    "\n",
    "# freeze backbone for first few epochs for stability on small data\n",
    "FROZEN_EPOCHS = 3\n",
    "set_backbone_requires_grad(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "987ad009",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/xdhs9djd73zb7hz3752jr1gh0000gn/T/ipykernel_70784/3446123123.py:5: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01/12 | train_loss 1.0127 acc 0.738 | val_loss 0.2509 acc 0.973 | 2.5s\n",
      "  ✅ Saved new best to runs/font_resnet/best.ckpt.pt (val_acc=0.973)\n",
      "Epoch 02/12 | train_loss 0.1193 acc 0.915 | val_loss 0.0232 acc 0.912 | 2.4s\n",
      "Epoch 03/12 | train_loss 0.0822 acc 0.845 | val_loss 0.0874 acc 0.876 | 2.4s\n",
      "Epoch 04/12 | train_loss 0.0604 acc 0.878 | val_loss 0.0064 acc 0.982 | 3.2s\n",
      "  ✅ Saved new best to runs/font_resnet/best.ckpt.pt (val_acc=0.982)\n",
      "Epoch 05/12 | train_loss 0.0197 acc 0.943 | val_loss 0.0714 acc 0.858 | 3.2s\n",
      "Epoch 06/12 | train_loss 0.0036 acc 0.958 | val_loss 0.0871 acc 0.956 | 3.3s\n",
      "Epoch 07/12 | train_loss 0.0023 acc 0.975 | val_loss 0.0023 acc 0.973 | 3.2s\n",
      "Epoch 08/12 | train_loss 0.0312 acc 0.945 | val_loss 0.0035 acc 0.973 | 3.2s\n",
      "Epoch 09/12 | train_loss 0.0430 acc 0.948 | val_loss 0.0022 acc 0.973 | 3.2s\n",
      "Epoch 10/12 | train_loss 0.0434 acc 0.907 | val_loss 0.0689 acc 0.876 | 3.4s\n",
      "Epoch 11/12 | train_loss 0.0150 acc 0.940 | val_loss 0.0028 acc 0.947 | 3.3s\n",
      "Epoch 12/12 | train_loss 0.0037 acc 0.967 | val_loss 0.0852 acc 0.973 | 3.3s\n",
      "Best val acc: 0.982\n"
     ]
    }
   ],
   "source": [
    "# ----------------------------\n",
    "# AMP for speed (CUDA only, MPS/CPU use no-op)\n",
    "# ----------------------------\n",
    "use_cuda_amp = (device.type == \"cuda\")\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n",
    "\n",
    "def maybe_autocast():\n",
    "    # Autocast only on CUDA; use no-op on MPS/CPU\n",
    "    return torch.cuda.amp.autocast(dtype=torch.float16) if use_cuda_amp else nullcontext()\n",
    "\n",
    "# ----------------------------\n",
    "# Train / Eval loops\n",
    "# ----------------------------\n",
    "best_val_acc = 0.0\n",
    "best_ckpt = Path(OUT_DIR) / \"best.ckpt.pt\"\n",
    "\n",
    "def run_epoch(loader, train=True):\n",
    "    model.train(mode=train)\n",
    "    running_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for images, targets in loader:\n",
    "        images = images.to(device, non_blocking=True)\n",
    "        targets = targets.to(device, non_blocking=True)\n",
    "\n",
    "        with torch.set_grad_enabled(train):\n",
    "            with maybe_autocast():\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, targets)\n",
    "\n",
    "            if train:\n",
    "                if use_cuda_amp:\n",
    "                    scaler.scale(loss).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "                else:\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    optimizer.zero_grad(set_to_none=True)\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += (preds == targets).sum().item()\n",
    "        total += targets.size(0)\n",
    "\n",
    "    avg_loss = running_loss / total if total else 0.0\n",
    "    acc = correct / total if total else 0.0\n",
    "    return avg_loss, acc\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    t0 = time.time()\n",
    "\n",
    "    # unfreeze after warmup\n",
    "    if epoch == FROZEN_EPOCHS:\n",
    "        unfreeze_all(model)\n",
    "        set_backbone_requires_grad(True)\n",
    "\n",
    "    train_loss, train_acc = run_epoch(train_loader, train=True)\n",
    "    val_loss, val_acc = run_epoch(val_loader, train=False)\n",
    "    scheduler.step()\n",
    "\n",
    "    dt = time.time() - t0\n",
    "    print(f\"Epoch {epoch+1:02d}/{EPOCHS} | \"\n",
    "          f\"train_loss {train_loss:.4f} acc {train_acc:.3f} | \"\n",
    "          f\"val_loss {val_loss:.4f} acc {val_acc:.3f} | {dt:.1f}s\")\n",
    "\n",
    "    # save best\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        torch.save({\n",
    "            \"model_state\": model.state_dict(),\n",
    "            \"classes\": full_ds.classes,\n",
    "            \"val_acc\": val_acc\n",
    "        }, best_ckpt)\n",
    "        print(f\"  ✅ Saved new best to {best_ckpt} (val_acc={val_acc:.3f})\")\n",
    "\n",
    "print(f\"Best val acc: {best_val_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ea8b8025",
   "metadata": {},
   "outputs": [],
   "source": [
    "full2 = datasets.ImageFolder(DATA_DIR)\n",
    "assert [full_ds.samples[i][0] for i in range(50)] == [full2.samples[i][0] for i in range(50)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "06148938",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Roboto': 0.0,\n",
       " 'Playfair_Display': 0.0,\n",
       " 'Roboto_Condensed': 0.0,\n",
       " 'Ubuntu': 0.0,\n",
       " 'Open_Sans': 0.0,\n",
       " 'Source_Sans_Pro': 0.0,\n",
       " 'Raleway': 0.0,\n",
       " 'Montserrat': 0.0,\n",
       " 'Poppins': 0.0,\n",
       " 'Inter': 1.0,\n",
       " 'Roboto_Mono': 0.0,\n",
       " 'Oswald': 0.0,\n",
       " 'Merriweather': 0.0,\n",
       " 'Lato': 0.0,\n",
       " 'Nunito': 0.0}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "model.eval()\n",
    "correct_per, total_per = Counter(), Counter()\n",
    "with torch.no_grad():\n",
    "    for imgs, t in val_loader:\n",
    "        o = model(imgs.to(device)).argmax(1).cpu()\n",
    "        for ti, pi in zip(t, o):\n",
    "            total_per[int(ti)] += 1\n",
    "            correct_per[int(ti)] += int(pi == ti)\n",
    "{ full_ds.classes[k]: correct_per[k] / total_per[k] for k in total_per }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28729030",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 8,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [11,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 5,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 9,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [10,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "all_p, all_t = [], []\n",
    "with torch.no_grad():\n",
    "    for x,y in val_loader:\n",
    "        all_p.append(model(x.to(device)).argmax(1).cpu())\n",
    "        all_t.append(y)\n",
    "cm = confusion_matrix(torch.cat(all_t), torch.cat(all_p))\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7c9ced",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fonts-arm64",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
